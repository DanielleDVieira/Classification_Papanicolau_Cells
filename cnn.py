# -*- coding: utf-8 -*-
"""Cópia de PAI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NU45velyyFmpeEN6tVDMyQfigFxe2bdW
"""

import pandas as pd
import matplotlib.pyplot as plt
import math
import cv2
import os
from collections import Counter
import numpy as np
from sklearn.model_selection import train_test_split
from scipy.spatial.distance import mahalanobis
from sklearn import metrics as me

"""# Open DF"""

df = pd.read_csv("./data/classifications.csv")
metrics = pd.read_csv("./data/metricsAll.csv", sep=';')

# Caminho para a pasta com as imagens
caminho_pasta = './cells'

# Lista para armazenar as imagens
imagens = []

# Loop pelos arquivos na pasta
for nome_arquivo in os.listdir(caminho_pasta):
    # Verifica se o arquivo é uma imagem (você pode adicionar mais extensões, se necessário)
    if nome_arquivo.endswith('.jpg') or nome_arquivo.endswith('.png'):
        # Caminho completo do arquivo
        caminho_arquivo = os.path.join(caminho_pasta, nome_arquivo)
        
        # Carrega a imagem usando o OpenCV
        imagem = cv2.imread(caminho_arquivo)
        
        # Redimensiona a imagem, se necessário (algumas redes neurais têm tamanhos específicos de entrada)
        largura, altura = 100, 100  # Defina as dimensões desejadas
        imagem_redimensionada = cv2.resize(imagem, (largura, altura))
        
        # Adiciona a imagem redimensionada à lista de imagens
        imagens.append(imagem_redimensionada)

# Converte a lista de imagens em um array numpy para ser usada como entrada para a rede
imagens_array = np.array(imagens)

# Verifica a forma (shape) do array de imagens
print("Shape do array de imagens: ", imagens_array.shape)
print("Quantidade imagens de celulas: ", len(imagens_array))

metrics.sort_values(by=['ID'], inplace=True)
metrics = metrics.reset_index()
del metrics['index']

df['MedoideCalculado'] = metrics['MedoideCalculado']
df['CoordCSV'] = metrics['CoordCSV']
df['DistanciaDoCentro'] = metrics['DistanciaDoCentro']
df['Area'] = metrics['Area']
df['Perimetro'] = metrics['Perimetro']
df['Compacidade'] = metrics['Compacidade']
df['Excentricidade'] = metrics['Excentricidade']

"""# Scatter Plot"""

df['bethesda_system'].unique()

scc = df[df['bethesda_system'] == 'SCC']
neg = df[df['bethesda_system'] == 'Negative for intraepithelial lesion']
lsi = df[df['bethesda_system'] == 'LSIL']
hsi = df[df['bethesda_system'] == 'HSIL']
ash = df[df['bethesda_system'] == 'ASC-H']
asu = df[df['bethesda_system'] == 'ASC-US']

plt.figure(figsize=(10,6))

scatter0 = plt.scatter(scc['Area'], scc['Excentricidade'], c='#ff0000', s=2, alpha=1, label='SCC')
scatter1 = plt.scatter(neg['Area'], neg['Excentricidade'], c='#000000', s=2, alpha=1, label='Negative')
scatter2 = plt.scatter(lsi['Area'], lsi['Excentricidade'], c='#00ff00', s=2, alpha=1, label='LSIL')
scatter3 = plt.scatter(hsi['Area'], hsi['Excentricidade'], c='#0000ff', s=2, alpha=1, label='HSIL')
scatter4 = plt.scatter(ash['Area'], ash['Excentricidade'], c='#440154', s=2, alpha=1, label='ASC-H')
scatter5 = plt.scatter(asu['Area'], asu['Excentricidade'], c='#00ffff', s=2, alpha=1, label='ASC-US')

plt.legend(title='Classes', loc="upper right", markerscale=2)
plt.xlabel("Área", size=15)
plt.ylabel("Excentricidade", size=15)
plt.tight_layout()
plt.show()

Counter(list(df['bethesda_system']))

"""# Train test split"""

print(scc.head())

sccFeatures = scc[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]
negFeatures = neg[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]
lsiFeatures = lsi[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]
hsiFeatures = hsi[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]
ashFeatures = ash[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]
asuFeatures = asu[['cell_id', 'Area', 'Perimetro', 'Compacidade', 'Excentricidade']]

X_train0, X_test0, y_train0, y_test0 = train_test_split(sccFeatures, scc['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)
X_train1, X_test1, y_train1, y_test1 = train_test_split(negFeatures, neg['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)
X_train2, X_test2, y_train2, y_test2 = train_test_split(lsiFeatures, lsi['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)
X_train3, X_test3, y_train3, y_test3 = train_test_split(hsiFeatures, hsi['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)
X_train4, X_test4, y_train4, y_test4 = train_test_split(ashFeatures, ash['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)
X_train5, X_test5, y_train5, y_test5 = train_test_split(asuFeatures, asu['bethesda_system'], test_size=0.2, train_size=0.8, shuffle=True, random_state=42)

X_train_neg = X_train1
X_test_neg = X_test1
y_train_neg = y_train1
y_test_neg = y_test1

X_train_positive = pd.concat([X_train0, X_train2, X_train3, X_train4, X_train5], ignore_index=True)
X_test_positive = pd.concat([X_test0, X_test2, X_test3, X_test4, X_test5], ignore_index=True)
y_train_positive = pd.concat([y_train0, y_train2, y_train3, y_train4, y_train5], ignore_index=True)
y_test_positive = pd.concat([y_test0, y_test2, y_test3, y_test4, y_test5], ignore_index=True)

y_test = pd.concat([y_test_neg, y_test_positive], ignore_index=True)

print(X_train_positive.head())
print(X_train_neg.head())

features_train_neg = X_train_neg.iloc[:, 1:5]
features_train_positive = X_train_positive.iloc[:, 1:5]

features_test_neg = X_test_neg.iloc[:, 1:5].to_numpy()
features_test_positive = X_test_positive.iloc[:, 1:5].to_numpy()

features_test = np.concatenate((features_test_neg, features_test_positive))
features_test_id = pd.concat([X_test_neg, X_test_positive], ignore_index=True)

# Calcular a matriz de covariância para a classe negativa
cov_neg = np.cov(features_train_neg, rowvar=False)
mean_neg = np.mean(features_train_neg, axis=0)

cov_positive = np.cov(features_train_positive, rowvar=False)
mean_positive = np.mean(features_train_positive, axis=0)

# Função para calcular a distância de Mahalanobis para a classe negativa
def mahalanobis_dist_neg(sample):
    return mahalanobis(sample, mean_neg, cov_neg)

def mahalanobis_dist_positive(sample):
    return mahalanobis(sample, mean_positive, cov_positive)

# Calcular a distância de Mahalanobis para cada amostra de teste
distances_neg = [mahalanobis_dist_neg(sample) for sample in features_test]

distances_positive = [mahalanobis_dist_positive(sample) for sample in features_test]

df['Classification'] = -1
classification = []

print(features_test_id)

for i in range(len(distances_neg)):
    if distances_neg[i] > distances_positive[i]:
        id = features_test_id.iloc[i]['cell_id']
        df.loc[df['cell_id'] == id, 'Classification'] = 1
        classification.append(1)
    else:
        id = features_test_id.iloc[i]['cell_id']
        df.loc[df['cell_id'] == id, 'Classification'] = 0       
        classification.append(0)
        
print(df['Classification'].value_counts())

y_test.replace({
    'Negative for intraepithelial lesion': 0,
    'HSIL': 1,
    'LSIL': 1,
    'ASC-H': 1,
    'ASC-US': 1,
    'SCC': 1
}, inplace=True)
print(y_test.value_counts())

acuracia = me.accuracy_score(y_test, classification)
print("Acurácia:", acuracia)

precisao = me.precision_score(y_test, classification)
print("Precisão:", precisao)

sensibilidade = me.recall_score(y_test, classification)
print("Sensibilidade (Revocação):", sensibilidade)

cm = me.confusion_matrix(y_test, classification)
classes = ['Negative', 'Positive']  # Mapeamento para 0 e 1
disp = me.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)
disp.plot(include_values=True, cmap='Blues', ax=None, xticks_rotation='horizontal')
# Modificando os rótulos do eixo x
plt.xticks(ticks=[0, 1], labels=classes)
# Adicionando título
plt.title('Matriz de confusão para classificação binária com Mahalanobis')
# Exibindo a matriz de confusão
plt.show()
